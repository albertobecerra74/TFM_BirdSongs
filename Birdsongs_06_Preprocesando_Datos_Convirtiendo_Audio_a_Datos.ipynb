{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Birdsongs - 06.- Preprocesando Datos - Convirtiendo Audio a Datos\n",
    "\n",
    "\n",
    "Convierte los ficheros de audio de un repositorio local a ficheros de datos en formato numpy array. En caso de interrupción se puede volver a lanzar y continua con el proceso copiando los restantes (si se quiere empezar de nuevo hay que eliminar los directorios de destino).\n",
    "\n",
    "La estructura de directorios de destino es la misma que los ficheros de audio. Esto permite luego tratar con los datos de forma más eficiente que tener que estar transformando los datos \"al vuelo\".\n",
    "\n",
    "![directorio](./resources/directorioaudios.png)\n",
    "\n",
    "\n",
    "Va procesando los audios que existen en cada subdirectorio y va creando un directorio de datos, con los ficheros numpy contiendo la información de la grabación. Vamos a tratar con dos tipos de datos\n",
    "\n",
    "### a) [Mel scale Spectrogram](https://en.wikipedia.org/wiki/Mel_scale)\n",
    "\n",
    ">The mel scale, named by Stevens, Volkmann, and Newman in 1937,[1] is a perceptual scale of pitches judged by listeners to be equal in distance from one another. The reference point between this scale and normal frequency measurement is defined by assigning a perceptual pitch of 1000 mels to a 1000 Hz tone, 40 dB above the listener's threshold. Above about 500 Hz, increasingly large intervals are judged by listeners to produce equal pitch increments. As a result, four octaves on the hertz scale above 500 Hz are judged to comprise about two octaves on the mel scale. The name mel comes from the word melody to indicate that the scale is based on pitch comparisons. \n",
    "\n",
    "\n",
    "\n",
    "MEL spectrogram es bastante utilizado en procesos de machine learning para tratamiento de audio y voz. \n",
    "\n",
    "\n",
    "https://github.com/adanRivas/CNN-Audio-Classifier-with-Keras-Tensorflow/blob/master/save_melspectograms.ipynb\n",
    "\n",
    "\n",
    "\n",
    "### b) [Welch's method Periodogram](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.welch.html#scipy.signal.welch)\n",
    "\n",
    ">Welch’s method computes an estimate of the power spectral density by dividing the data into overlapping segments, computing a modified periodogram for each segment and averaging the periodograms.\n",
    ">\n",
    ">In physics, engineering, and applied mathematics, Welch's method, named after P.D. Welch, is used for estimating the power of a signal at different frequencies: that is, it is an approach to spectral density estimation. The method is based on the concept of using periodogram spectrum estimates, which are the result of converting a signal from the time domain to the frequency domain. Welch's method is an improvement on the standard periodogram spectrum estimating method and on Bartlett's method, in that it reduces noise in the estimated power spectra in exchange for reducing the frequency resolution. Due to the noise caused by imperfect and finite data, the noise reduction from Welch's method is often desired. \n",
    "\n",
    "\n",
    "El resultado de este notebook es la generación de un directorio con los audios transformados a datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Librerías\n",
    "\n",
    "Cargamos las librerías de uso común.\n",
    "\n",
    "Para el tratamiento de los audios vamos a utilizar [**libROsa**](http://librosa.github.io/librosa/). Es una librería que nos permite convertir los audios en datos, y a su vez, transformarlos en información útil en el campo de análisis de señales: oscilogramas, espectrogramas, MFCC,... Además, la ventaja que tiene frente a otras librerías, es que permite leer los audios directamente en mp3, cosa que otras librerías del tipo [PySoundfile](https://pypi.org/project/SoundFile/) o  [Soundfile](https://pysoundfile.readthedocs.io/en/0.9.0/) no soportan.\n",
    "\n",
    "> LibROSA is a python package for music and audio analysis. It provides the building blocks necessary to create music information retrieval systems.\n",
    "\n",
    "      conda install -c conda-forge librosa \n",
    "     \n",
    "Y también utilizaremos [**scipy**](https://docs.scipy.org/doc/scipy/reference/), para el cálculo de periodogramas.\n",
    "\n",
    ">SciPy (pronounced “Sigh Pie”) is a Python-based ecosystem of open-source software for mathematics, science, and engineering. In particular, these are some of the core packages:\n",
    "     \n",
    "      conda install -c anaconda scipy\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar librerías\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.signal as signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Funciones\n",
    "\n",
    "Funciones utilizadas en el notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recupera directorios\n",
    "\n",
    "Los ficheros de audio se encuentran localizados en un directorio raíz, y dentro del correspondiente subdirectorio al que pertenece la especie. Realizando un dir de los directorios contenidos en el directorio raíz, tendremos una lista con todas las especies que forman parte del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------\n",
    "# get_specie_names(path)\n",
    "#  argumentos: \n",
    "#      path: directorio de audios\n",
    "#----------------------------------------------------------------------------\n",
    "def get_specie_names(path):  \n",
    "    specie_names = os.listdir(path)\n",
    "    return specie_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesa audios\n",
    "\n",
    "Procesa los audios que existen en cada subdirectorio y va creando un directorio de datos, con los ficheros numpy contiendo la información de la grabación en el formato pasado por parámetro.\n",
    "\n",
    "##### No se generan MFCC, para ello, descomentar el código\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------\n",
    "# process_audio(audiopath, datatype, melpath, mfccpath, welchpath)\n",
    "#  argumentos: \n",
    "#      audiopath: repositorio de audios\n",
    "#      datatype: tipo de datos\n",
    "#      melpath: repositorio de destino para Espectrogramas de MEL\n",
    "#      mfccpath: repositorio de destino para MFCC\n",
    "#      welchpath: repositorio de destino para periodogramas Welch\n",
    "#----------------------------------------------------------------------------\n",
    "def process_audio(audiopath, datatype, melpath, mfccpath, welchpath):\n",
    "    print(\">>>> procesando audios...\")\n",
    "    \n",
    "    # crea el directorio raiz de datos\n",
    "    if datatype == CT_MEL:\n",
    "        if not os.path.exists(melpath):\n",
    "            os.mkdir(melpath)\n",
    "\n",
    "        #if not os.path.exists(mfccpath):\n",
    "        #    os.mkdir(mfccpath)\n",
    "            \n",
    "    elif datatype == CT_WELCH:\n",
    "        if not os.path.exists(welchpath):\n",
    "            os.mkdir(welchpath)\n",
    "        \n",
    "    # recupera la lista de especies (directorios) a tratar\n",
    "    specie_names = get_specie_names(audiopath)\n",
    "    number_species = len(specie_names)\n",
    "   \n",
    "    # itera sobre cada directorio y va generando un fichero con los MEL spectrogram\n",
    "    for idx, specie_name in enumerate(specie_names):\n",
    "        # crea directorio destino de la especie según el tipo\n",
    "        if datatype == CT_MEL:\n",
    "            meldir = os.path.join(melpath, specie_name)\n",
    "            if not os.path.exists(meldir):\n",
    "                os.mkdir(meldir)\n",
    "\n",
    "           # mfccdir = os.path.join(mfccpath, specie_name)\n",
    "           # if not os.path.exists(mfccdir):\n",
    "           #     os.mkdir(mfccdir)\n",
    "\n",
    "        elif datatype == CT_WELCH:\n",
    "            welchdir = os.path.join(welchpath, specie_name)\n",
    "            if not os.path.exists(welchdir):\n",
    "                os.mkdir(welchdir)\n",
    "                \n",
    "                \n",
    "        # recupera los ficheros de audio existentes para esta especie\n",
    "        specie_dir = os.path.join(audiopath, specie_name)\n",
    "        specie_files = os.listdir(specie_dir)\n",
    "        number_files = len(specie_files)\n",
    "        number_load = number_files\n",
    "        \n",
    "        print(' Specie name = {:14s} - {:3d}'.format(specie_name,idx),\n",
    "               \", \",number_files,\" files in this specie\", sep=\" \", end='\\r', flush=True)\n",
    "\n",
    "        # itera sobre la lista de audios recuperada\n",
    "        printevery = 20\n",
    "        \n",
    "        for idx2, infilename in enumerate(specie_files):\n",
    "            # fichero audio origen\n",
    "            file_path = specie_dir + '/' + infilename\n",
    "\n",
    "            # muestra avance\n",
    "            if (0 == idx2 % printevery):\n",
    "                print('\\r Loading specie: {:14s} ({:2d} of {:2d} species)'.format(specie_name,idx+1,number_species),\n",
    "                       \", file \",idx2+1,\" of \",number_load,\": \",file_path, sep=\" \", end='\\r', flush=True)\n",
    "\n",
    "            # nombre del audio\n",
    "            file_name = infilename[:infilename.find('.')]\n",
    "            \n",
    "            # MEL espectrograma\n",
    "            if datatype == CT_MEL:\n",
    "            \n",
    "                # si no se ha generado previamente, procedemos a generarlo    \n",
    "                melfile = meldir + '/' + file_name +'_mel.npy'\n",
    "                #mfccfile = mfccdir + '/' + file_name +'_mfcc.npy'\n",
    "            \n",
    "                if not os.path.isfile(melfile):\n",
    "                    # lee fichero\n",
    "                    aud, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "                    # genera el log MEL spectrogram\n",
    "                    melgram = librosa.feature.melspectrogram(aud, sr=sr, n_mels=128)\n",
    "                    log_melgram = librosa.amplitude_to_db(melgram, ref=np.max)\n",
    "\n",
    "                    # salva fichero numpy \n",
    "                    np.save(melfile,log_melgram)\n",
    "                    \n",
    "                    # genera el MFCC\n",
    "                    #mfcc = librosa.feature.mfcc(S=log_melgram, n_mfcc=20)\n",
    "                    #np.save(mfccfile,mfcc)\n",
    "                    \n",
    "            # Welch Periodogram\n",
    "            elif datatype == CT_WELCH:\n",
    "                # si no se ha generado previamente, procedemos a generarlo    \n",
    "                welchfile = welchdir + '/' + file_name +'_welch.npy'\n",
    "            \n",
    "                if not os.path.isfile(welchfile):\n",
    "                    # lee fichero\n",
    "                    aud, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "                    # genera el periodograma Welch\n",
    "                    welchgram = signal.welch(aud, sr, \"flattop\", 11024, scaling=\"spectrum\")\n",
    "\n",
    "                    # salva fichero numpy \n",
    "                    np.save(welchfile,welchgram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Convierte audio en datos\n",
    "\n",
    "Lanza el proceso de conversión de todos los audios localizados en el repositorio al formato de dato especificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# constantes\n",
    "CT_MEL = 'MEL'\n",
    "CT_WELCH = 'WELCH'\n",
    "\n",
    "# repositorio con los audios\n",
    "audiopath = './audio'\n",
    "\n",
    "# tipo de dato a generar\n",
    "datatype = CT_WELCH\n",
    "\n",
    "# repositorios de generación de los datos\n",
    "melpath= './data/mel2'\n",
    "mfccpath= './data/mfcc2'\n",
    "welchpath= './data/welch2'\n",
    "\n",
    "# genera datos a partir de los audios\n",
    "process_audio(audiopath, datatype, melpath, mfccpath, welchpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
